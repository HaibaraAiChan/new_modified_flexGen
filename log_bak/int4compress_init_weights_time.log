<run_flexgen>: args.model: facebook/opt-6.7b
model size: 12.386 GB, cache size: 0.562 GB, hidden size (prefill): 0.009 GB
init weight...
start create model 
init all weights 
the time init all weights  22.74569082260132
the model construction time  23.090813636779785
   model structure 
InputEmbed
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
OutputEmbed

the useful data start from here -------------------------------------
benchmark - generate
args.gen_len  32
input  torch.Size([4, 256])
============ generate loop normal ============
generate start -----
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 5.21124267578125 GB
    Memory Allocated: 3.8976526260375977  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12155.17578125}
---------================-------------------after mha 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.9264020919799805  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------after mha 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12196.1640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.8976526260375977  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12196.88671875}
---------================-------------------after mha 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.9259138107299805  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------after mha 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12196.88671875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.8976526260375977  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12196.88671875}
---------================-------------------after mha 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.9259138107299805  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------after mha 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12196.88671875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.8976526260375977  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12196.88671875}
---------================-------------------after mha 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.9259138107299805  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------after mha 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.8976526260375977  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
---------================-------------------after mha 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.9259138107299805  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------after mha 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.8976526260375977  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
---------================-------------------after mha 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.9259138107299805  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------after mha 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.8976526260375977  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
---------================-------------------after mha 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.9259138107299805  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------after mha 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.8976526260375977  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
---------================-------------------after mha 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.9259138107299805  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------after mha 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.8976526260375977  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
---------================-------------------after mha 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.9259138107299805  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------after mha 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.8976526260375977  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
---------================-------------------after mha 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.9259138107299805  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------after mha 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.8976526260375977  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
---------================-------------------after mha 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.9259138107299805  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------after mha 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.8976526260375977  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
---------================-------------------after mha 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.9259138107299805  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------after mha 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.8976526260375977  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
---------================-------------------after mha 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.9259138107299805  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------after mha 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.8976526260375977  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
---------================-------------------after mha 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.9259138107299805  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------after mha 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.8976526260375977  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
---------================-------------------after mha 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.9259138107299805  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------after mha 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.8976526260375977  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
---------================-------------------after mha 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.9259138107299805  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------after mha 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.8976526260375977  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
---------================-------------------after mha 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.9259138107299805  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------after mha 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.8976526260375977  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
---------================-------------------after mha 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.9259138107299805  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------after mha 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.8976526260375977  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
---------================-------------------after mha 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.9259138107299805  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------after mha 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.8976526260375977  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
---------================-------------------after mha 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.9259138107299805  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------after mha 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.8976526260375977  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
---------================-------------------after mha 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.9259138107299805  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------after mha 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.8976526260375977  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
---------================-------------------after mha 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.9259138107299805  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------after mha 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.8976526260375977  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
---------================-------------------after mha 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.9259138107299805  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------after mha 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.8976526260375977  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
---------================-------------------after mha 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.9259138107299805  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------after mha 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.8976526260375977  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
---------================-------------------after mha 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.9259138107299805  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------after mha 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.8976526260375977  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
---------================-------------------after mha 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.9259138107299805  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------after mha 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.8976526260375977  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
---------================-------------------after mha 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.9259138107299805  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------after mha 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.8976526260375977  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
---------================-------------------after mha 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.9259138107299805  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------after mha 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.8976526260375977  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
---------================-------------------after mha 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.9259138107299805  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------after mha 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.8976526260375977  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
---------================-------------------after mha 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.9259138107299805  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------after mha 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.8976526260375977  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
---------================-------------------after mha 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.9259138107299805  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------after mha 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.8976526260375977  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
---------================-------------------after mha 

 Nvidia-smi: 5.27960205078125 GB
    Memory Allocated: 3.9259138107299805  GigaBytes
Max Memory Allocated: 4.237744331359863  GigaBytes

---------================-------------------after mha 
{'VmPeak': 32323.4140625, 'VmSize': 31005.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.0625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.30859375}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.30859375}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.30859375}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.30859375}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.30859375}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.30859375}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.30859375}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.30859375}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.30859375}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.30859375}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.30859375}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.30859375}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.30859375}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.30859375}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.30859375}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.30859375}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.30859375}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.30859375}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.30859375}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.30859375}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.30859375}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.30859375}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.30859375}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.30859375}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.30859375}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.30859375}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.30859375}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.30859375}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.30859375}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.30859375}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.30859375}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.30859375}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.30859375}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.30859375}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.30859375}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.30859375}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.30859375}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.30859375}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.30859375}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.30859375}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.30859375}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.30859375}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.30859375}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 5.37725830078125 GB
    Memory Allocated: 3.899653911590576  GigaBytes
Max Memory Allocated: 4.245553016662598  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 32323.4140625, 'VmSize': 31133.140625, 'VmHWM': 14272.03515625, 'VmRSS': 12197.546875}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
the model generate time  9.374003410339355
Outputs:
----------------------------------------------------------------------
0: Paris is the capital city of France and the most visited city in the world. It is the capital of the Ile-de-France region, and the seat of the French government.
----------------------------------------------------------------------
3: Paris is the capital city of France and the most visited city in the world. It is the capital of the Ile-de-France region, and the seat of the French government.
----------------------------------------------------------------------

TorchDevice: cuda:0
  cur_mem: 3.5986 GB,  peak_mem: 4.2456 GB
TorchDevice: cpu
  cur_mem: 0.0000 GB,  peak_mem: 0.0000 GB
model size: 12.386 GB	cache size: 0.562 GB	hidden size (p): 0.009 GB
peak gpu mem: 4.246 GB	projected: False
prefill latency: 0.674 s	prefill throughput: 1519.201 token/s
decode latency: 8.693 s	decode throughput: 14.264 token/s
total latency: 9.367 s	total throughput: 13.665 token/s
