<run_flexgen>: args.model: facebook/opt-6.7b
model size: 12.386 GB, cache size: 0.562 GB, hidden size (prefill): 0.009 GB
init weight...
start create model 
init all weights 
the time init all weights  13.330108880996704
the model construction time  13.444885015487671
   model structure 
InputEmbed
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
SelfAttention
prefill  None
MLP
OutputEmbed

the useful data start from here -------------------------------------
benchmark - generate
args.gen_len  32
input  torch.Size([4, 256])
============ generate loop normal ============
generate start -----
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 14.38702392578125 GB
    Memory Allocated: 13.362092018127441  GigaBytes
Max Memory Allocated: 13.369912147521973  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 36778.6015625, 'VmSize': 36752.75390625, 'VmHWM': 10968.97265625, 'VmRSS': 10585.171875}
---------================-------------------after mha 

 Nvidia-smi: 14.50616455078125 GB
    Memory Allocated: 13.401461601257324  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------after mha 
{'VmPeak': 36988.3203125, 'VmSize': 36956.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10765.390625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.362092018127441  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10765.7890625}
---------================-------------------after mha 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.401461601257324  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------after mha 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10765.7890625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.362092018127441  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10765.7890625}
---------================-------------------after mha 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.401461601257324  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------after mha 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10765.7890625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.362092018127441  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10765.7890625}
---------================-------------------after mha 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.401461601257324  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------after mha 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10765.7890625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.362092018127441  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
---------================-------------------after mha 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.401461601257324  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------after mha 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.362092018127441  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
---------================-------------------after mha 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.401461601257324  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------after mha 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.362092018127441  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
---------================-------------------after mha 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.401461601257324  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------after mha 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.362092018127441  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
---------================-------------------after mha 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.401461601257324  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------after mha 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.362092018127441  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
---------================-------------------after mha 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.401461601257324  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------after mha 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.362092018127441  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
---------================-------------------after mha 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.401461601257324  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------after mha 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.362092018127441  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
---------================-------------------after mha 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.401461601257324  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------after mha 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.362092018127441  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
---------================-------------------after mha 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.401461601257324  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------after mha 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.362092018127441  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
---------================-------------------after mha 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.401461601257324  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------after mha 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.362092018127441  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
---------================-------------------after mha 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.401461601257324  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------after mha 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.362092018127441  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
---------================-------------------after mha 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.401461601257324  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------after mha 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.362092018127441  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
---------================-------------------after mha 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.401461601257324  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------after mha 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.362092018127441  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
---------================-------------------after mha 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.401461601257324  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------after mha 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.362092018127441  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
---------================-------------------after mha 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.401461601257324  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------after mha 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.362092018127441  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
---------================-------------------after mha 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.401461601257324  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------after mha 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.362092018127441  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
---------================-------------------after mha 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.401461601257324  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------after mha 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.362092018127441  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
---------================-------------------after mha 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.401461601257324  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------after mha 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.362092018127441  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
---------================-------------------after mha 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.401461601257324  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------after mha 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.362092018127441  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
---------================-------------------after mha 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.401461601257324  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------after mha 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.362092018127441  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
---------================-------------------after mha 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.401461601257324  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------after mha 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.362092018127441  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
---------================-------------------after mha 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.401461601257324  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------after mha 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.362092018127441  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
---------================-------------------after mha 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.401461601257324  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------after mha 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.362092018127441  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
---------================-------------------after mha 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.401461601257324  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------after mha 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.362092018127441  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
---------================-------------------after mha 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.401461601257324  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------after mha 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.362092018127441  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
---------================-------------------after mha 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.401461601257324  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------after mha 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.362092018127441  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
---------================-------------------after mha 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.401461601257324  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------after mha 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.362092018127441  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
---------================-------------------after mha 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.401461601257324  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------after mha 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention prefill--------
mha prefill----------------
---------================-------------------before q, k, v 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.362092018127441  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------before q, k, v 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
---------================-------------------after mha 

 Nvidia-smi: 14.53741455078125 GB
    Memory Allocated: 13.401461601257324  GigaBytes
Max Memory Allocated: 13.417087078094482  GigaBytes

---------================-------------------after mha 
{'VmPeak': 37020.3203125, 'VmSize': 36988.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.203125}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 256, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.6640625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
------------------------layer name  InputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------************   number of head
self attention decode =======
mha_gen decode----------------
---------================-------------------after mha_gen 

 Nvidia-smi: 14.63507080078125 GB
    Memory Allocated: 13.346620082855225  GigaBytes
Max Memory Allocated: 13.45016622543335  GigaBytes

---------================-------------------after mha_gen 
{'VmPeak': 37148.3203125, 'VmSize': 37116.32421875, 'VmHWM': 10968.97265625, 'VmRSS': 10766.90625}
------------------------layer name  SelfAttention
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  MLP
hidden  TorchTensor(shape=torch.Size([4, 1, 4096]), dtype=torch.float16, device=cuda:0)
------------------------layer name  OutputEmbed
hidden  TorchTensor(shape=torch.Size([4, 1]), dtype=torch.int64, device=cuda:0)
generate stop *******
the model generate time  1.5848159790039062
Outputs:
----------------------------------------------------------------------
0: Paris is the capital city of France and the most visited city in the world. It is the most visited city in the world, with more than 30 million visitors each year. Paris is the
----------------------------------------------------------------------
3: Paris is the capital city of France and the most visited city in the world. It is the most visited city in the world, with more than 30 million visitors each year. Paris is the
----------------------------------------------------------------------

TorchDevice: cuda:0
  cur_mem: 12.7859 GB,  peak_mem: 13.4502 GB
TorchDevice: cpu
  cur_mem: 0.0000 GB,  peak_mem: 0.0000 GB
model size: 12.386 GB	cache size: 0.562 GB	hidden size (p): 0.009 GB
peak gpu mem: 13.450 GB	projected: False
prefill latency: 0.484 s	prefill throughput: 2116.215 token/s
decode latency: 1.093 s	decode throughput: 113.438 token/s
total latency: 1.577 s	total throughput: 81.167 token/s
